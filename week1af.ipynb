{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# This function opens a file and retrieves all lines in this file.\n",
    "# It then removes all whitespace from this line and then creates a list with\n",
    "# where the first item is genre, the second item is the sentiment, and the\n",
    "# third is the id number of the review. Everything after this are the words\n",
    "# of the review. To retrieve sentiment the variable use_sentiment must be True.\n",
    "# To use genre's the variable use_sentiment must be False. One of these\n",
    "# variables will be used as labels. It then returns the documents and labels.\n",
    "def read_corpus(corpus_file, use_sentiment):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "\n",
    "            documents.append(tokens[3:])\n",
    "\n",
    "            if use_sentiment:\n",
    "                # 2-class problem: positive vs negative\n",
    "                labels.append( tokens[1] )\n",
    "            else:\n",
    "                # 6-class problem: books, camera, dvd, health, music, software\n",
    "                labels.append( tokens[0] )\n",
    "\n",
    "    return documents, labels\n",
    "    \n",
    "# a dummy function that just returns its input\n",
    "def identity(x):\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.7913333333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.73      0.92      0.81       731\n",
      "         pos       0.90      0.67      0.77       769\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1500\n",
      "   macro avg       0.81      0.79      0.79      1500\n",
      "weighted avg       0.81      0.79      0.79      1500\n",
      "\n",
      "||                   pos|                   neg\n",
      "__________________________________________________\n",
      "pos                 |         673|         58\n",
      "neg                 |         255|         514\n",
      "\n",
      "\n",
      "Prior probabilty pos: 0.48733333333333334 \n",
      "\n",
      "Prior probabilty neg: 0.5126666666666667 \n",
      "\n",
      "posterior probability:  [[0.45254975 0.54745025]\n",
      " [0.64883268 0.35116732]\n",
      " [0.715697   0.284303  ]\n",
      " ...\n",
      " [0.36157777 0.63842223]\n",
      " [0.55175648 0.44824352]\n",
      " [0.69005043 0.30994957]]\n"
     ]
    }
   ],
   "source": [
    "# The program reads a textfile and retrieves the data\n",
    "# and the labels linked to the data. After this it\n",
    "# splits the data in training data and test data.\n",
    "# The same goes for the labels.\n",
    "X, Y = read_corpus('trainset.txt', use_sentiment=True)\n",
    "split_point = int(0.75*len(X))\n",
    "Xtrain = X[:split_point]\n",
    "Ytrain = Y[:split_point]\n",
    "Xtest = X[split_point:]\n",
    "Ytest = Y[split_point:]\n",
    "total_instances = len(Xtest)\n",
    "\n",
    "\n",
    "\n",
    "# A TF_IDF vectorizer creates a score scale based on frequency of input\n",
    "# within different documents. Every word will have a different score for\n",
    "# a different document. This score can be used as feature for the classifier.\n",
    "# The classifier learns from these features in order to make calculated\n",
    "# predictions.\n",
    "# let's use the TF-IDF vectorizer\n",
    "tfidf = True\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# we use a dummy function as tokenizer and preprocessor,\n",
    "# since the texts are already preprocessed and tokenized.\n",
    "if tfidf:\n",
    "    vec = TfidfVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "#The CountVectorizer creates a score scale based on frequency of input only\n",
    "# This is can be used to create a baseline to see how other machine learning\n",
    "# techniques compare.    \n",
    "else:\n",
    "    vec = CountVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "\n",
    "# combine the vectorizer with a Naive Bayes classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=False))] )\n",
    "\n",
    "\n",
    "# Here the classifier learns which feautures are linked to what label.\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "\n",
    "# Here the classifier predicts the label of features based on the\n",
    "# learned process in the step before.  \n",
    "Yguess = classifier.predict(Xtest)\n",
    "\n",
    "# Here the classifier compares the gold standard labels with the\n",
    "# predict labels retrieved from the step before.\n",
    "print(\"accuracy score: \", accuracy_score(Ytest, Yguess))\n",
    "\n",
    "# Here the system tries to predict the labels of the test data, where\n",
    "# Yguess are the predicted labels and Xtest is the data\n",
    "\n",
    "print(classification_report(Ytest, Yguess))\n",
    "\n",
    "#prints confusion matrix\n",
    "\n",
    "labels=['pos','neg']\n",
    "cm=confusion_matrix(Ytest, Yguess,)\n",
    "c = 0\n",
    "print(\"{0}\".format(\"|\"), *labels, sep=\"{0:20}\".format(\"|\"))\n",
    "print(\"_\"*50)\n",
    "for h in labels:\n",
    "    print(\"{0:<20}\".format(h), *cm[c], sep=\"{0:<10}\".format(\"|\"))\n",
    "\n",
    "    c += 1\n",
    "\n",
    "# print prior probabilities per class\n",
    "\n",
    "print(\"\\n\")\n",
    "c = 0    \n",
    "for h in labels:\n",
    "    print(\"Prior probabilty {0}: {1} \\n\".format(h, (sum(cm[c]) / total_instances)))\n",
    "    c += 1\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "# print posterior probabilities per class\n",
    "\n",
    "print(\"posterior probability: \",classifier. predict_proba(X))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score:  0.894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       books       0.91      0.91      0.91       233\n",
      "      camera       0.82      0.94      0.87       258\n",
      "         dvd       0.88      0.87      0.87       242\n",
      "      health       0.98      0.79      0.88       243\n",
      "       music       0.95      0.92      0.93       260\n",
      "    software       0.86      0.93      0.89       264\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1500\n",
      "   macro avg       0.90      0.89      0.89      1500\n",
      "weighted avg       0.90      0.89      0.89      1500\n",
      "\n",
      "|         books|         camera|         dvd|         health|         music|         software\n",
      "__________________________________________________\n",
      "books               |       212|       3|       9|       0|       0|       9\n",
      "camera              |       0|       243|       1|       2|       1|       11\n",
      "dvd                 |       9|       9|       210|       0|       10|       4\n",
      "health              |       2|       34|       0|       193|       1|       13\n",
      "music               |       2|       0|       16|       1|       238|       3\n",
      "software            |       7|       9|       3|       0|       0|       245\n",
      "\n",
      "\n",
      "Prior probabilty books: 0.15533333333333332 \n",
      "\n",
      "Prior probabilty camera: 0.172 \n",
      "\n",
      "Prior probabilty dvd: 0.16133333333333333 \n",
      "\n",
      "Prior probabilty health: 0.162 \n",
      "\n",
      "Prior probabilty music: 0.17333333333333334 \n",
      "\n",
      "Prior probabilty software: 0.176 \n",
      "\n",
      "posterior probability:  [[9.41602688e-04 5.66293976e-01 3.45364554e-04 1.26536193e-02\n",
      "  1.82019175e-01 2.37746262e-01]\n",
      " [5.49647848e-47 2.54211933e-67 1.00000000e+00 1.05769227e-82\n",
      "  1.07974773e-45 2.92800115e-79]\n",
      " [7.39150304e-09 2.86560123e-06 1.23241223e-09 9.99997125e-01\n",
      "  9.76742330e-10 2.84103631e-10]\n",
      " ...\n",
      " [4.07956735e-29 1.30826927e-46 6.80504119e-25 9.72980343e-58\n",
      "  1.00000000e+00 4.04319920e-45]\n",
      " [8.71637247e-06 8.38846530e-05 9.18472597e-02 6.08961188e-12\n",
      "  9.82446576e-05 9.07961895e-01]\n",
      " [2.01829377e-21 1.00000000e+00 2.66852201e-20 6.20294094e-23\n",
      "  3.08587035e-23 6.02906028e-16]]\n"
     ]
    }
   ],
   "source": [
    "# Same as previous cell\n",
    "X, Y = read_corpus('trainset.txt', use_sentiment=False)\n",
    "split_point = int(0.75*len(X))\n",
    "Xtrain = X[:split_point]\n",
    "Ytrain = Y[:split_point]\n",
    "Xtest = X[split_point:]\n",
    "Ytest = Y[split_point:]\n",
    "total_instances = len(Xtest)\n",
    "\n",
    "\n",
    "tfidf = False\n",
    "\n",
    "if tfidf:\n",
    "    vec = TfidfVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "else:\n",
    "    vec = CountVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "\n",
    "# combine the vectorizer with a Naive Bayes classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', MultinomialNB())] )\n",
    "\n",
    "\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "\n",
    "Yguess = classifier.predict(Xtest)\n",
    "\n",
    "print(\"accuracy score: \", accuracy_score(Ytest, Yguess))\n",
    "\n",
    "\n",
    "print(classification_report(Ytest, Yguess))\n",
    "\n",
    "labels=['books', 'camera', 'dvd', 'health', 'music', 'software']\n",
    "cm=confusion_matrix(Ytest, Yguess, labels=labels)\n",
    "c = 0\n",
    "print(\"{0}\".format(\"\"), *labels, sep=\"{0:10}\".format(\"|\"))\n",
    "print(\"_\"*50)\n",
    "for h in labels:\n",
    "    print(\"{0:<20}\".format(h), *cm[c], sep=\"{0:<8}\".format(\"|\"))\n",
    "    c += 1\n",
    "\n",
    "print(\"\\n\")\n",
    "c = 0    \n",
    "for h in labels:\n",
    "    print(\"Prior probabilty {0}: {1} \\n\".format(h, (sum(cm[c]) / total_instances)))\n",
    "    c += 1\n",
    "\n",
    "\n",
    "print(\"posterior probability: \",classifier. predict_proba(X))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
