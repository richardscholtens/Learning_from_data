{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# COMMENT THIS\n",
    "def read_corpus(corpus_file, use_sentiment):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "\n",
    "            documents.append(tokens[3:])\n",
    "\n",
    "            if use_sentiment:\n",
    "                # 2-class problem: positive vs negative\n",
    "                labels.append( tokens[1] )\n",
    "            else:\n",
    "                # 6-class problem: books, camera, dvd, health, music, software\n",
    "                labels.append( tokens[0] )\n",
    "\n",
    "    return documents, labels\n",
    "    \n",
    "# a dummy function that just returns its input\n",
    "def identity(x):\n",
    "    return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.71      0.93      0.81       731\n",
      "         pos       0.91      0.64      0.75       769\n",
      "\n",
      "   micro avg       0.78      0.78      0.78      1500\n",
      "   macro avg       0.81      0.79      0.78      1500\n",
      "weighted avg       0.81      0.78      0.78      1500\n",
      "\n",
      "||                   pos|                   neg\n",
      "__________________________________________________\n",
      "pos                 |         683|         48\n",
      "neg                 |         279|         490\n",
      "['neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
      " 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos' 'pos' 'neg' 'pos'\n",
      " 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg' 'neg'\n",
      " 'neg' 'pos' 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
      " 'pos' 'neg' 'neg' 'neg' 'pos' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'pos'\n",
      " 'neg' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg' 'neg' 'pos' 'neg' 'pos' 'neg'\n",
      " 'pos' 'pos' 'pos' 'neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neg' 'pos' 'neg' 'pos' 'pos' 'neg' 'pos' 'pos' 'neg' 'neg' 'pos' 'neg'\n",
      " 'pos' 'neg']\n"
     ]
    }
   ],
   "source": [
    "# COMMENT THIS\n",
    "X, Y = read_corpus('trainset.txt', use_sentiment=True)\n",
    "split_point = int(0.75*len(X))\n",
    "Xtrain = X[:split_point]\n",
    "Ytrain = Y[:split_point]\n",
    "Xtest = X[split_point:]\n",
    "Ytest = Y[split_point:]\n",
    "\n",
    "# let's use the TF-IDF vectorizer\n",
    "tfidf = True\n",
    "\n",
    "# we use a dummy function as tokenizer and preprocessor,\n",
    "# since the texts are already preprocessed and tokenized.\n",
    "if tfidf:\n",
    "    vec = TfidfVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "else:\n",
    "    vec = CountVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "\n",
    "# combine the vectorizer with a Naive Bayes classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', MultinomialNB())] )\n",
    "\n",
    "\n",
    "# COMMENT THIS\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "\n",
    "# COMMENT THIS  \n",
    "Yguess = classifier.predict(Xtest)\n",
    "\n",
    "# COMMENT THIS\n",
    "print(accuracy_score(Ytest, Yguess))\n",
    "\n",
    "#print(precision_recall_fscore_support(Ytest, Yguess, average='macro'))\n",
    "#print(precision_recall_fscore_support(Ytest, Yguess, average='micro'))\n",
    "#print(precision_recall_fscore_support(Ytest, Yguess, average='weighted'))\n",
    "\n",
    "\n",
    "print(classification_report(Ytest, Yguess))\n",
    "\n",
    "\n",
    "labels=['pos','neg']\n",
    "cm=confusion_matrix(Ytest, Yguess,)\n",
    "c = 0\n",
    "print(\"{0}\".format(\"|\"), *labels, sep=\"{0:20}\".format(\"|\"))\n",
    "print(\"_\"*50)\n",
    "for h in labels:\n",
    "    print(\"{0:<20}\".format(h), *cm[c], sep=\"{0:<10}\".format(\"|\"))\n",
    "    c += 1\n",
    "    \n",
    "classifier.fit(X, Y)\n",
    "print(classifier.predict(X[2:100]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9066666666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       books       0.94      0.91      0.93       233\n",
      "      camera       0.83      0.94      0.88       258\n",
      "         dvd       0.88      0.91      0.89       242\n",
      "      health       0.97      0.79      0.87       243\n",
      "       music       0.96      0.95      0.95       260\n",
      "    software       0.89      0.93      0.91       264\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1500\n",
      "   macro avg       0.91      0.91      0.91      1500\n",
      "weighted avg       0.91      0.91      0.91      1500\n",
      "\n",
      "|         books|         camera|         dvd|         health|         music|         software\n",
      "__________________________________________________\n",
      "books               |       213|       2|       12|       1|       0|       5\n",
      "camera              |       1|       242|       2|       3|       1|       9\n",
      "dvd                 |       5|       6|       220|       0|       9|       2\n",
      "health              |       2|       33|       4|       192|       1|       11\n",
      "music               |       1|       0|       9|       0|       247|       3\n",
      "software            |       4|       10|       3|       1|       0|       246\n"
     ]
    }
   ],
   "source": [
    "# COMMENT THIS\n",
    "X, Y = read_corpus('trainset.txt', use_sentiment=False)\n",
    "split_point = int(0.75*len(X))\n",
    "Xtrain = X[:split_point]\n",
    "Ytrain = Y[:split_point]\n",
    "Xtest = X[split_point:]\n",
    "Ytest = Y[split_point:]\n",
    "\n",
    "# let's use the TF-IDF vectorizer\n",
    "tfidf = True\n",
    "\n",
    "# we use a dummy function as tokenizer and preprocessor,\n",
    "# since the texts are already preprocessed and tokenized.\n",
    "if tfidf:\n",
    "    vec = TfidfVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "else:\n",
    "    vec = CountVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "\n",
    "# combine the vectorizer with a Naive Bayes classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', MultinomialNB())] )\n",
    "\n",
    "\n",
    "# COMMENT THIS\n",
    "classifier.fit(Xtrain, Ytrain)\n",
    "\n",
    "# COMMENT THIS  \n",
    "Yguess = classifier.predict(Xtest)\n",
    "\n",
    "# COMMENT THIS\n",
    "print(accuracy_score(Ytest, Yguess))\n",
    "\n",
    "#print(precision_recall_fscore_support(Ytest, Yguess, average='macro'))\n",
    "#print(precision_recall_fscore_support(Ytest, Yguess, average='micro'))\n",
    "#print(precision_recall_fscore_support(Ytest, Yguess, average='weighted'))\n",
    "\n",
    "\n",
    "\n",
    "print(classification_report(Ytest, Yguess))\n",
    "\n",
    "labels=['books', 'camera', 'dvd', 'health', 'music', 'software']\n",
    "cm=confusion_matrix(Ytest, Yguess, labels=labels)\n",
    "c = 0\n",
    "print(\"{0}\".format(\"\"), *labels, sep=\"{0:10}\".format(\"|\"))\n",
    "print(\"_\"*50)\n",
    "for h in labels:\n",
    "    print(\"{0:<20}\".format(h), *cm[c], sep=\"{0:<8}\".format(\"|\"))\n",
    "    c += 1\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
